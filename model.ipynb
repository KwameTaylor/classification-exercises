{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Exercises\n",
    "## Logistic Regression\n",
    "\n",
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "from prepare import titanic_split, prep_titanic\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  sex_male  embarked_Q  \\\n",
       "0         0       3  22.0      1      0   7.2500      0         1           0   \n",
       "1         1       1  38.0      1      0  71.2833      0         0           0   \n",
       "2         1       3  26.0      0      0   7.9250      1         0           0   \n",
       "3         1       1  35.0      1      0  53.1000      0         0           0   \n",
       "4         0       3  35.0      0      0   8.0500      1         1           0   \n",
       "\n",
       "   embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First I will make import titanic.csv into a dataframe\n",
    "# In the same step, I will tidy the data for a first time\n",
    "\n",
    "df = prep_titanic()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived      0\n",
       "pclass        0\n",
       "age           0\n",
       "sibsp         0\n",
       "parch         0\n",
       "fare          0\n",
       "alone         0\n",
       "sex_male      0\n",
       "embarked_Q    0\n",
       "embarked_S    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to check for nulls\n",
    "\n",
    "df.isnull().sum(axis=0)\n",
    "\n",
    "# There no nulls and I see that my imputer in my prepare.py has sufficiently tidied the data for me now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 2) , validate:  (214, 2) , test:  (178, 2)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now, before I do anything else with this data, I will split it into train, validate, and test.\n",
    "\n",
    "X1 = df[['pclass','fare']]\n",
    "y1 = df[['survived']]\n",
    "\n",
    "X1_train_validate, X1_test, y1_train_validate, y1_test = train_test_split(X1, y1, test_size = .20, random_state = 666)\n",
    "\n",
    "X1_train, X1_validate, y1_train, y1_validate = train_test_split(X1_train_validate, y1_train_validate, test_size = .30, random_state = 666)\n",
    "\n",
    "print(\"train: \", X1_train.shape, \", validate: \", X1_validate.shape, \", test: \", X1_test.shape)\n",
    "print(\"train: \", y1_train.shape, \", validate: \", y1_validate.shape, \", test: \", y1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start by defining your baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For my own reference:\n",
    "\n",
    "# accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "# recall = tp / (tp + fn)\n",
    "# precision = tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    299\n",
       "1    198\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the baseline and it's accuracy\n",
    "\n",
    "y1_train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived\n",
       "88          1\n",
       "386         0\n",
       "459         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline (and our positive case) will that be a passenger did Not Survive.\n",
    "\n",
    "baseline_model = pd.DataFrame(y1_train)\n",
    "baseline_model.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline\n",
       "88        1         0\n",
       "386       0         0\n",
       "459       0         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model[\"baseline\"] = baseline_model.survived.value_counts().index[0]\n",
    "baseline_model = baseline_model.rename(columns={'survived': 'actual'})\n",
    "baseline_model.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>baseline</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "baseline    0\n",
       "actual       \n",
       "0         299\n",
       "1         198"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(baseline_model.actual, baseline_model.baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 299\n",
      "False Positives: 198\n",
      "False Negatives: 0\n",
      "True Negatives: 0\n",
      "-------------\n",
      "Accuracy of baseline model is 0.602\n"
     ]
    }
   ],
   "source": [
    "# Positive is Not Survived\n",
    "\n",
    "tp = 299\n",
    "tn = 0\n",
    "fp = 198\n",
    "fn = 0\n",
    "\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"-------------\")\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "print(\"Accuracy of baseline model is\", round(accuracy, 3))\n",
    "#print(\"Recall is\", round(recall, 3))\n",
    "#print(\"Precision is\", round(precision, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now I know that in order to beat my baseline model's accuracy,\n",
    "> I must build a model with over 60% accuracy in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create another model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 3) , validate:  (214, 3) , test:  (178, 3)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# I will create a new model adding age on the X.\n",
    "\n",
    "X2 = df[['pclass','fare', 'age']]\n",
    "y2 = df[['survived']]\n",
    "\n",
    "X2_train_validate, X2_test, y2_train_validate, y2_test = train_test_split(X2, y2, test_size = .20, random_state = 666)\n",
    "\n",
    "X2_train, X2_validate, y2_train, y2_validate = train_test_split(X2_train_validate, y2_train_validate, test_size = .30, random_state = 666)\n",
    "\n",
    "print(\"train: \", X2_train.shape, \", validate: \", X2_validate.shape, \", test: \", X2_test.shape)\n",
    "print(\"train: \", y2_train.shape, \", validate: \", y2_validate.shape, \", test: \", y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, Fit, & Predict\n",
    "\n",
    "# Create the logistic regression object\n",
    "logit = LogisticRegression(C=1, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=666)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "\n",
    "logit.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.88326135  0.00685142 -0.03761418]]\n",
      "Intercept: \n",
      " [2.42863895]\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y2_pred = logit.predict(X2_train)\n",
    "#y2_pred\n",
    "#above commented out unless you want a bunch of zeros and ones on your screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability of a passenger surviving, using the training data\n",
    "\n",
    "y2_pred_proba = logit.predict_proba(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model on Train\n",
    "\n",
    "# Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X2_train, y2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 69% accuracy is better than our baseline model accuracy of 60% without age and without using a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 4) , validate:  (214, 4) , test:  (178, 4)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# My model already has sex encoded as sex_male (1 meaning the passenger is male), so I will leave that alone for now.\n",
    "# I will create a new model adding sex on the X.\n",
    "\n",
    "X3 = df[['pclass','fare', 'age', 'sex_male']]\n",
    "y3 = df[['survived']]\n",
    "\n",
    "X3_train_validate, X3_test, y3_train_validate, y3_test = train_test_split(X3, y3, test_size = .20, random_state = 666)\n",
    "\n",
    "X3_train, X3_validate, y3_train, y3_validate = train_test_split(X3_train_validate, y3_train_validate, test_size = .30, random_state = 666)\n",
    "\n",
    "print(\"train: \", X3_train.shape, \", validate: \", X3_validate.shape, \", test: \", X3_test.shape)\n",
    "print(\"train: \", y3_train.shape, \", validate: \", y3_validate.shape, \", test: \", y3_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, Fit, & Predict\n",
    "\n",
    "# Create the logistic regression object\n",
    "logit2 = LogisticRegression(C=1, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=666)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "\n",
    "logit2.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.11869479  0.00322321 -0.03718728 -2.67597258]]\n",
      "Intercept: \n",
      " [4.5650524]\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit2.coef_)\n",
    "print('Intercept: \\n', logit2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y3_pred = logit2.predict(X3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability of a passenger surviving, using the training data\n",
    "\n",
    "y3_pred_proba = logit2.predict_proba(X3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model on Train\n",
    "\n",
    "# Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X3_train, y3_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Accuracy of this model is 81%, making it the best model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 4) , validate:  (214, 4) , test:  (178, 4)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# For this next model I will take out fare and add in alone as a variable.\n",
    "\n",
    "X4 = df[['pclass', 'age', 'sex_male', 'alone']]\n",
    "y4 = df[['survived']]\n",
    "\n",
    "X4_train_validate, X4_test, y4_train_validate, y4_test = train_test_split(X4, y4, test_size = .20, random_state = 666)\n",
    "\n",
    "X4_train, X4_validate, y4_train, y4_validate = train_test_split(X4_train_validate, y4_train_validate, test_size = .30, random_state = 666)\n",
    "\n",
    "print(\"train: \", X4_train.shape, \", validate: \", X4_validate.shape, \", test: \", X4_test.shape)\n",
    "print(\"train: \", y4_train.shape, \", validate: \", y4_validate.shape, \", test: \", y4_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, Fit, & Predict\n",
    "\n",
    "# Create the logistic regression object\n",
    "logit3 = LogisticRegression(C=1, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=666)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "\n",
    "logit3.fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.20732769 -0.03708502 -2.66698316 -0.14040183]]\n",
      "Intercept: \n",
      " [4.93553074]\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit3.coef_)\n",
    "print('Intercept: \\n', logit3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y4_pred = logit3.predict(X4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability of a passenger surviving, using the training data\n",
    "\n",
    "y4_pred_proba = logit3.predict_proba(X4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model on Train\n",
    "\n",
    "# Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit3.score(X4_train, y4_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This model has 81% accuracy, same as the last model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 7) , validate:  (214, 7) , test:  (178, 7)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# For the next model I'll just try adding all of the features I think are most relevant.\n",
    "# This might be a little overkill on the features, but I am curious to see if it improves accuracy.\n",
    "\n",
    "X5 = df[['pclass', 'fare', 'age', 'sex_male', 'alone', 'sibsp', 'parch']]\n",
    "y5 = df[['survived']]\n",
    "\n",
    "X5_train_validate, X5_test, y5_train_validate, y5_test = train_test_split(X5, y5, test_size = .20, random_state = 666)\n",
    "\n",
    "X5_train, X5_validate, y5_train, y5_validate = train_test_split(X5_train_validate, y5_train_validate, test_size = .30, random_state = 666)\n",
    "\n",
    "print(\"train: \", X5_train.shape, \", validate: \", X5_validate.shape, \", test: \", X5_test.shape)\n",
    "print(\"train: \", y5_train.shape, \", validate: \", y5_validate.shape, \", test: \", y5_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, Fit, & Predict\n",
    "\n",
    "# Create the logistic regression object\n",
    "logit4 = LogisticRegression(C=1, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=666)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "\n",
    "logit4.fit(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.0395119   0.00347852 -0.04213193 -2.67400127 -0.76392875 -0.50163724\n",
      "  -0.16848647]]\n",
      "Intercept: \n",
      " [5.28808292]\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit4.coef_)\n",
    "print('Intercept: \\n', logit4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y5_pred = logit4.predict(X5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability of a passenger surviving, using the training data\n",
    "\n",
    "y5_pred_proba = logit4.predict_proba(X5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model on Train\n",
    "\n",
    "# Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit4.score(X5_train, y5_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 82% is the accuracy of this model, so it is the best model, and the one with the most included features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 will be the model with features pclass, fare, age, and sex_male.\n",
      "Accuracy of Logistic Regression classifier on validation set: 0.79\n",
      "Confusion matrix:\n",
      " [[126  15]\n",
      " [ 31  42]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.85       141\n",
      "           1       0.74      0.58      0.65        73\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.77      0.73      0.75       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Model 2 will be the model with features pclass, age, sex_male, and alone.\n",
      "Accuracy of Logistic Regression classifier on validation set: 0.79\n",
      "Confusion matrix:\n",
      " [[126  15]\n",
      " [ 31  42]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.85       141\n",
      "           1       0.74      0.58      0.65        73\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.77      0.73      0.75       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Model 3 will be the model with features pclass, fare, age, sex_male, alone, sibsp, and parch.\n",
      "Accuracy of Logistic Regression classifier on validation set: 0.80\n",
      "Confusion matrix:\n",
      " [[130  11]\n",
      " [ 31  42]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       141\n",
      "           1       0.79      0.58      0.67        73\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.75      0.76       214\n",
      "weighted avg       0.80      0.80      0.79       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = logit2.predict(X3_validate)\n",
    "y_pred2 = logit3.predict(X4_validate)\n",
    "y_pred3 = logit4.predict(X5_validate)\n",
    "\n",
    "print('Model 1 will be the model with features pclass, fare, age, and sex_male.')\n",
    "print('Accuracy of Logistic Regression classifier on validation set: {:.2f}'\n",
    "     .format(logit2.score(X3_validate, y3_validate)))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y3_validate, y_pred1))\n",
    "print(\"Classification report:\\n\", classification_report(y3_validate, y_pred1))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------\\n\")\n",
    "\n",
    "print('Model 2 will be the model with features pclass, age, sex_male, and alone.')\n",
    "print('Accuracy of Logistic Regression classifier on validation set: {:.2f}'\n",
    "     .format(logit3.score(X4_validate, y4_validate)))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y4_validate, y_pred2))\n",
    "print(\"Classification report:\\n\", classification_report(y4_validate, y_pred2))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------\\n\")\n",
    "\n",
    "print('Model 3 will be the model with features pclass, fare, age, sex_male, alone, sibsp, and parch.')\n",
    "print('Accuracy of Logistic Regression classifier on validation set: {:.2f}'\n",
    "     .format(logit4.score(X5_validate, y5_validate)))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y5_validate, y_pred3))\n",
    "print(\"Classification report:\\n\", classification_report(y5_validate, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 is the model with features pclass, fare, age, sex_male, alone, sibsp, and parch.\n",
      "Accuracy of Logistic Regression classifier on test set: 0.76\n",
      "Confusion matrix:\n",
      " [[90 19]\n",
      " [24 45]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       109\n",
      "           1       0.70      0.65      0.68        69\n",
      "\n",
      "    accuracy                           0.76       178\n",
      "   macro avg       0.75      0.74      0.74       178\n",
      "weighted avg       0.76      0.76      0.76       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3 performed best so I will use that one on the test dataset.\n",
    "\n",
    "y_pred4 = logit4.predict(X5_test)\n",
    "\n",
    "print('Model 3 is the model with features pclass, fare, age, sex_male, alone, sibsp, and parch.')\n",
    "print('Accuracy of Logistic Regression classifier on test set: {:.2f}'\n",
    "     .format(logit4.score(X5_test, y5_test)))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y5_test, y_pred4))\n",
    "print(\"Classification report:\\n\", classification_report(y5_test, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model 3 performed on the test dataset with an accuracy of 76%, lower than the 80% accuracy it achieved on the validate dataset. The f1-score on test is 81%, compared to 86% on validate. On the train dataset, Model 3's accuracy was 82%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Exercises Cont.\n",
    "## Decision Trees\n",
    "\n",
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "Continue working in your model file. Add, commit, and push your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  sex_male  embarked_Q  \\\n",
       "0         0       3  22.0      1      0   7.2500      0         1           0   \n",
       "1         1       1  38.0      1      0  71.2833      0         0           0   \n",
       "2         1       3  26.0      0      0   7.9250      1         0           0   \n",
       "3         1       1  35.0      1      0  53.1000      0         0           0   \n",
       "4         0       3  35.0      0      0   8.0500      1         1           0   \n",
       "\n",
       "   embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prep_titanic()\n",
    "df.head(5)\n",
    "\n",
    "# Survived is 1, not survived is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 9) , validate:  (214, 9) , test:  (178, 9)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now, before I do anything else with this data, I will split it into train, validate, and test.\n",
    "\n",
    "X1 = df.drop(['survived'],axis=1)\n",
    "y1 = df[['survived']]\n",
    "\n",
    "X1_train_validate, X1_test, y1_train_validate, y1_test = train_test_split(X1, y1, test_size = .20, random_state = 666)\n",
    "\n",
    "X1_train, X1_validate, y1_train, y1_validate = train_test_split(X1_train_validate, y1_train_validate, test_size = .30, random_state = 666)\n",
    "\n",
    "print(\"train: \", X1_train.shape, \", validate: \", X1_validate.shape, \", test: \", X1_test.shape)\n",
    "print(\"train: \", y1_train.shape, \", validate: \", y1_validate.shape, \", test: \", y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>3</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass        age  sibsp  parch    fare  alone  sex_male  embarked_Q  \\\n",
       "88        1  23.000000      3      2  263.00      0         0           0   \n",
       "386       3   1.000000      5      2   46.90      0         1           0   \n",
       "459       3  29.642093      0      0    7.75      1         1           1   \n",
       "\n",
       "     embarked_S  \n",
       "88            1  \n",
       "386           1  \n",
       "459           0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "# Create the Decision Tree Object\n",
    "# for classification you can change the algorithm to gini or entropy (information gain).  Default is gini.\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=666)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred = clf.predict(X1_train)\n",
    "y1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0462963 , 0.9537037 ],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.        , 1.        ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.0462963 , 0.9537037 ],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.72727273, 0.27272727],\n",
       "       [0.41428571, 0.58571429],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.94117647, 0.05882353],\n",
       "       [0.94117647, 0.05882353]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred_proba = clf.predict_proba(X1_train)\n",
    "y1_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.84\n",
      "Confusion matrix:\n",
      " [[262  37]\n",
      " [ 45 153]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       299\n",
      "           1       0.81      0.77      0.79       198\n",
      "\n",
      "    accuracy                           0.84       497\n",
      "   macro avg       0.83      0.82      0.83       497\n",
      "weighted avg       0.83      0.84      0.83       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X1_train, y1_train)))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y1_train, y1_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y1_train, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred\n",
    "y1_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y1_train, y1_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 153\n",
      "False Positives: 37\n",
      "False Negatives: 45\n",
      "True Negatives: 262\n",
      "-------------\n",
      "Accuracy is 0.835\n",
      "Recall is 0.773\n",
      "Precision is 0.805\n",
      "Specificity is 0.876\n",
      "f1-score is 0.789\n",
      "Support is [299 198]\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "specificity= (tn / (tn + fp))\n",
    "\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "print(\"True Negatives:\", tn)\n",
    "\n",
    "print(\"-------------\")\n",
    "\n",
    "print(\"Accuracy is\", round(accuracy, 3))\n",
    "print(\"Recall is\", round(recall, 3))\n",
    "print(\"Precision is\", round(precision, 3))\n",
    "print(\"Specificity is\", round(specificity, 3))\n",
    "print(\"f1-score is\", round(f1_score(y1_train, y1_pred), 3))\n",
    "print(\"Support is\", precision_recall_fscore_support(y1_train, y1_pred)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth=7, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, random_state=666)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred = clf2.predict(X1_train)\n",
    "y1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.35      , 0.65      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.35      , 0.65      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.66666667, 0.33333333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.66666667, 0.33333333],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.66666667, 0.33333333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.5       , 0.5       ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [1.        , 0.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35      , 0.65      ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8974359 , 0.1025641 ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95121951, 0.04878049],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.62745098, 0.37254902],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8974359 , 0.1025641 ]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred_proba = clf2.predict_proba(X1_train)\n",
    "y1_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.91\n",
      "Confusion matrix:\n",
      " [[288  11]\n",
      " [ 36 162]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       299\n",
      "           1       0.94      0.82      0.87       198\n",
      "\n",
      "    accuracy                           0.91       497\n",
      "   macro avg       0.91      0.89      0.90       497\n",
      "weighted avg       0.91      0.91      0.90       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf2.score(X1_train, y1_train)))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y1_train, y1_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y1_train, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model 2, with a max_depth of 7, outperformed Model 1 (max_depth of 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 will be the model with max_depth of 3.\n",
      "Accuracy of Decision Tree classifier on validation set: 0.81\n",
      "Confusion matrix:\n",
      " [[128  13]\n",
      " [ 27  46]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.86       141\n",
      "           1       0.78      0.63      0.70        73\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.77      0.78       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Model 2 will be the model with max_depth of 7.\n",
      "Accuracy of Decision Tree classifier on validation set: 0.78\n",
      "Confusion matrix:\n",
      " [[127  14]\n",
      " [ 34  39]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       141\n",
      "           1       0.74      0.53      0.62        73\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.72      0.73       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y1_pred = clf.predict(X1_validate)\n",
    "y2_pred = clf2.predict(X1_validate)\n",
    "\n",
    "print('Model 1 will be the model with max_depth of 3.')\n",
    "print('Accuracy of Decision Tree classifier on validation set: {:.2f}'\n",
    "     .format(clf.score(X1_validate, y1_validate)))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y1_validate, y1_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y1_validate, y1_pred))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------\\n\")\n",
    "\n",
    "print('Model 2 will be the model with max_depth of 7.')\n",
    "print('Accuracy of Decision Tree classifier on validation set: {:.2f}'\n",
    "     .format(clf2.score(X1_validate, y1_validate)))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y1_validate, y2_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y1_validate, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model 1 outperformed Model 2 on the validation dataset. My takeaway from this is that creating a max_depth of 7 overfitted it, as it greatly performed better on the train data than on the validate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Exercises Cont.\n",
    "## Random Forest\n",
    "\n",
    "Continue working in your model file. Be sure to add, commit, and push your changes.\n",
    "\n",
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20.\n",
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "### 4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3.\n",
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
